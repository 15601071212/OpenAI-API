# 如何使用大型语言模型
## 大型语言模型的工作原理
> 大型语言模型是将文本映射到文本的函数。给定一串输入文本，大型语言模型预测接下来应该出现的文本。

大型语言模型的魔力在于，通过训练以最小化这种预测错误，覆盖大量文本，模型最终学会了对这些预测有用的概念。例如，它们学会了：

- 如何拼写
- 语法如何运作
- 如何改述
- 如何回答问题
- 如何进行对话
- 如何用多种语言写作
- 如何编程
- 等等
  
> 它们通过“阅读”大量现有文本并学习单词如何在其他单词的上下文中出现，以及使用它所学到的来预测响应用户请求的下一个最可能出现的单词，以及之后的每一个单词。

> GPT-3和GPT-4为许多软件产品提供动力，包括生产力应用程序、教育应用程序、游戏等。

## 如何控制大型语言模型
> 在所有输入到大型语言模型的内容中，最有影响力的远远是文本提示。

大型语言模型可以通过几种方式被提示产生输出：

- **指令**：告诉模型你想要什么
- **完成**：诱导模型完成你想要的开始部分
- **场景**：给模型一个情境去展开
- **示范**：通过以下方式向模型展示你想要的：
  - 在提示中给出几个例子
  - 在微调训练数据集中给出数百或数千个例子
    
> 下面展示了每种方式的示例。

### 指令提示

> 在提示的顶部（或底部，或两者都有）写下你的指令，模型将尽力遵循指令然后停止。指令可以很详细，所以不要害怕写一个明确详细输出要求的段落，只需注意模型可以处理的令牌数量。

指令提示示例：

```text
从下面的引用中提取作者的名字。

“一些人类理论认为，智能物种在能够扩展到外太空之前就会灭绝。如果他们是对的，那么夜空的寂静就是坟场的沉默。”
― 特德·姜，呼吸
```

输出：

```text
特德·姜
```
### 完成提示示例

> 完成式提示利用了大型语言模型尝试编写它认为最有可能接下来出现的文本的方式。为了引导模型，尝试开始一个模式或句子，输出将完成你想看到的内容。相对于直接指令，这种引导大型语言模型的方式可能需要更多的关心和实验。此外，模型不一定知道在哪里停止，所以你通常需要停止序列或后处理来切断超出所需输出的生成文本。

完成提示示例：

```text
“一些人类理论认为，智能物种在能够扩展到外太空之前就会灭绝。如果他们是对的，那么夜空的寂静就是坟场的沉默。”
― 特德·姜，呼吸

这句引用的作者是
```

输出：

```text
特德·姜
```

### 场景提示示例

> 给模型一个要遵循的场景或要扮演的角色，对于复杂的查询或寻求富有想象力的回应很有帮助。使用假设性提示时，你设定一个情境、问题或故事，然后要求模型作为该场景中的一个角色或主题的专家来响应。

场景提示示例：
```text
你的角色是从任何给定文本中提取作者的名字

“一些人类理论认为，智能物种在能够扩展到外太空之前就会灭绝。如果他们是对的，那么夜空的寂静就是坟场的沉默。”
― 特德·姜，呼吸
```

输出：

```text
特德·姜
```

### 示范提示示例（少量学习）

> 类似于完成式提示，示范可以向模型展示你希望它做什么。这种方法有时被称为少量学习，因为模型从提示中提供的几个例子中学习。

示范提示示例：
```text
引用：
“当理性思维被迫一次又一次地面对不可能时，它别无选择，只能适应。”
― N.K. 杰米森，第五季
作者：N.K. 杰米森

引用：
“一些人类理论认为，智能物种在能够扩展到外太空之前就会灭绝。如果他们是对的，那么夜空的寂静就是坟场的沉默。”
― 特德·姜，呼吸
作者：
```

输出：

```text
特德·姜
```

### 微调提示示例

> 有足够的训练示例，你可以微调一个定制模型。在这种情况下，指令变得不必要，因为模型可以从提供的训练数据中学习任务。然而，包含分隔序列（例如，-> 或 ### 或任何不常出现在你的输入中的字符串）来告诉模型提示何时结束以及输出应该开始的地方可能是有帮助的。没有分隔序列，模型可能继续详述输入文本，而不是开始你想看到的答案。

微调提示示例（对于已经在类似的提示-完成对上进行了定制训练的模型）：

```text
“一些人类理论认为，智能物种在能够扩展到外太空之前就会灭绝。如果他们是对的，那么夜空的寂静就是坟场的沉默。”
― 特德·姜，呼吸

###
```

输出：

```text
特德·姜
```

## 代码能力

> 大型语言模型不仅在文本处理方面表现出色——它们在代码方面也很出色。OpenAI的GPT-4模型就是一个很好的例子。

GPT-4为众多创新产品提供动力，包括：

GitHub Copilot（在Visual Studio和其他IDE中自动完成代码）
Replit（可以完成、解释、编辑和生成代码）
Cursor（在为与AI配对编程设计的编辑器中更快地构建软件）
GPT-4比之前的模型如gpt-3.5-turbo-instruct更先进。但是，为了从GPT-4中获得最佳的编码任务效果，给出清晰和具体的指令仍然很重要。因此，设计好的提示可能需要更多的关心。

### 更多提示建议
> 要获得更多提示示例，请访问OpenAI Examples。

通常，输入提示是改善模型输出的最佳杠杆。你可以尝试一些技巧，比如：

- **更具体** 例如，如果你希望输出是逗号分隔的列表，请要求它返回一个逗号分隔的列表。如果你希望它在不知道答案时说“我不知道”，告诉它‘如果你不知道答案，请说“我不知道”。’你的指令越具体，模型响应得越好。
- **提供上下文**：帮助模型理解你请求的更大背景。这可能是背景信息、你想要的示例/演示或解释你的任务目的。
- **要求模型像专家一样回答。** 明确要求模型产生高质量的输出或像专家一样写的输出，可以诱导模型给出它认为专家会写的更高质量的答案。像“详细解释”或“逐步描述”的短语可以很有效。
- **提示模型写下解释其推理的一系列步骤。** 如果理解答案背后的‘为什么’很重要，提示模型包含其推理。这可以通过在每个答案之前简单地添加一行像“让我们一步一步思考”这样的话来完成。
